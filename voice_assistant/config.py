# voice_assistant/config.py

import os
from dotenv import load_dotenv

# Load environment variables from the .env file
load_dotenv()

class Config:
    """
    Configuration class to hold the model selection and API keys.
    
    Attributes:
        TRANSCRIPTION_MODEL (str): The model to use for transcription ('openai', 'groq', 'deepgram', 'fastwhisperapi', 'fastwhisper_local', 'local').
        RESPONSE_MODEL (str): The model to use for response generation ('openai', 'groq', 'ollama', 'local').
        TTS_MODEL (str): The model to use for text-to-speech ('openai', 'deepgram', 'elevenlabs', 'kokoro_local', 'kokoro_V2', 'melotts', 'cartesia', 'piper', 'local').
        OPENAI_API_KEY (str): API key for OpenAI services.
        GROQ_API_KEY (str): API key for Groq services.
        DEEPGRAM_API_KEY (str): API key for Deepgram services.
        ELEVENLABS_API_KEY (str): API key for ElevenLabs services.
        LOCAL_MODEL_PATH (str): Path to the local model.
    """
    # Model selection - UPDATED for local processing
    # STT Model options:
    # - 'fastwhisper_local': Direct local faster-whisper (RECOMMENDED - no HTTP)
    # - 'fastwhisperapi': HTTP-based faster-whisper (deprecated)
    # - 'openai': OpenAI Whisper API
    # - 'groq': Groq Whisper API
    # - 'deepgram': Deepgram STT API
    TRANSCRIPTION_MODEL = 'fastwhisper_local'  # Changed to local processing
    
    # Response Model (no changes needed)
    RESPONSE_MODEL = 'ollama'  # possible values: openai, groq, ollama
    
    # TTS Model options:
    # - 'kokoro_local': Direct local Kokoro TTS (RECOMMENDED - no HTTP)
    # - 'kokoro_V2': HTTP-based Kokoro streaming (deprecated)
    # - 'kokoro': HTTP-based Kokoro (deprecated)
    # - 'openai': OpenAI TTS API
    # - 'deepgram': Deepgram TTS API
    # - 'elevenlabs': ElevenLabs TTS API
    # - 'melotts': MeloTTS local model
    # - 'cartesia': Cartesia TTS API
    # - 'piper': Piper TTS local model
    TTS_MODEL = 'kokoro_local'  # Changed to local processing
    
    # Local Model Paths for Direct Processing
    # Kokoro TTS Model Files (download from Kokoro ONNX releases)
    KOKORO_MODEL_PATH = os.getenv("KOKORO_MODEL_PATH", "voice_assistant/kokoro-v1.0.onnx")
    KOKORO_VOICES_PATH = os.getenv("KOKORO_VOICES_PATH", "voice_assistant/voices-v1.0.bin")
    
    # Faster-Whisper Model Configuration
    WHISPER_MODEL_SIZE = os.getenv("WHISPER_MODEL_SIZE", "medium")  # tiny, base, small, medium, large
    WHISPER_DEVICE = os.getenv("WHISPER_DEVICE", "auto")  # auto, cpu, cuda
    WHISPER_COMPUTE_TYPE = os.getenv("WHISPER_COMPUTE_TYPE", "int8")  # int8, float16, float32

    # # Piper Server configuration
    # PIPER_SERVER_URL = os.getenv("PIPER_SERVER_URL")
    # PIPER_OUTPUT_FILE = "output.wav"

    # currently using the MeloTTS for local models. here is how to get started:
    # https://github.com/myshell-ai/MeloTTS/blob/main/docs/install.md#linux-and-macos-install

    # LLM Selection

    # OLLAMA_LLM="llama3.2:3b" 
    OLLAMA_LLM="gpt-oss:20b"
    # GROQ_LLM="llama3-8b-8192"
    # OPENAI_LLM="gpt-4o"

    # Ollama OpenAI SDK Configuration
    OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434/v1")
    OLLAMA_TEMPERATURE = float(os.getenv("OLLAMA_TEMPERATURE", "0.7"))

    # API keys and paths
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    GROQ_API_KEY = os.getenv("GROQ_API_KEY")
    DEEPGRAM_API_KEY = os.getenv("DEEPGRAM_API_KEY")
    ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
    LOCAL_MODEL_PATH = os.getenv("LOCAL_MODEL_PATH")
    CARTESIA_API_KEY = os.getenv("CARTESIA_API_KEY")

    # for serving the MeloTTS model (deprecated - now using direct processing)
    TTS_PORT_LOCAL = 5150
    TTS_PORT_LOCAL_V2 = 8000

    # temp file generated by the initial STT model
    INPUT_AUDIO = "test.mp3"

    @staticmethod
    def validate_config():
        """
        Validate the configuration to ensure all necessary environment variables are set.
        
        Raises:
            ValueError: If a required environment variable is not set.
        """
        Config._validate_model('TRANSCRIPTION_MODEL', [
            'openai', 'groq', 'deepgram', 'fastwhisperapi', 'fastwhisper_local', 'local'])
        Config._validate_model('RESPONSE_MODEL', [
            'openai', 'groq', 'ollama', 'local'])
        Config._validate_model('TTS_MODEL', [
            'openai', 'deepgram', 'elevenlabs', 'melotts', 'cartesia', 'kokoro_local', 'kokoro_V2', 'kokoro', 'local', 'piper'])

        Config._validate_api_key('TRANSCRIPTION_MODEL', 'openai', 'OPENAI_API_KEY')
        Config._validate_api_key('TRANSCRIPTION_MODEL', 'groq', 'GROQ_API_KEY')
        Config._validate_api_key('TRANSCRIPTION_MODEL', 'deepgram', 'DEEPGRAM_API_KEY')

        Config._validate_api_key('RESPONSE_MODEL', 'openai', 'OPENAI_API_KEY')
        Config._validate_api_key('RESPONSE_MODEL', 'groq', 'GROQ_API_KEY')

        Config._validate_api_key('TTS_MODEL', 'openai', 'OPENAI_API_KEY')
        Config._validate_api_key('TTS_MODEL', 'deepgram', 'DEEPGRAM_API_KEY')
        Config._validate_api_key('TTS_MODEL', 'elevenlabs', 'ELEVENLABS_API_KEY')
        Config._validate_api_key('TTS_MODEL', 'cartesia', 'CARTESIA_API_KEY')
        
        # Validate local model paths for local processing
        if Config.TTS_MODEL == 'kokoro_local':
            Config._validate_local_file('KOKORO_MODEL_PATH', Config.KOKORO_MODEL_PATH, 'Kokoro ONNX model')
            Config._validate_local_file('KOKORO_VOICES_PATH', Config.KOKORO_VOICES_PATH, 'Kokoro voices')

    @staticmethod
    def _validate_model(attribute, valid_options):
        model = getattr(Config, attribute)
        if model not in valid_options:
            raise ValueError(
                f"Invalid {attribute}. Must be one of {valid_options}"
            )
        
    @staticmethod
    def _validate_api_key(model_attr, model_value, api_key_attr):
        if getattr(Config, model_attr) == model_value and not getattr(Config, api_key_attr):
            raise ValueError(f"{api_key_attr} is required for {model_value} models")
    
    @staticmethod
    def _validate_local_file(attr_name, file_path, description):
        """Validate that a local file exists for local processing."""
        if not os.path.exists(file_path):
            raise ValueError(f"{description} file not found at {file_path}. Please ensure {attr_name} is set correctly.")
    
    @staticmethod
    def get_local_config_info():
        """Get information about local processing configuration."""
        return {
            "transcription": {
                "model": Config.TRANSCRIPTION_MODEL,
                "local_processing": Config.TRANSCRIPTION_MODEL == 'fastwhisper_local',
                "whisper_model_size": Config.WHISPER_MODEL_SIZE,
                "whisper_device": Config.WHISPER_DEVICE,
                "whisper_compute_type": Config.WHISPER_COMPUTE_TYPE
            },
            "tts": {
                "model": Config.TTS_MODEL,
                "local_processing": Config.TTS_MODEL == 'kokoro_local',
                "kokoro_model_path": Config.KOKORO_MODEL_PATH,
                "kokoro_voices_path": Config.KOKORO_VOICES_PATH
            },
            "response": {
                "model": Config.RESPONSE_MODEL,
                "ollama_llm": Config.OLLAMA_LLM if Config.RESPONSE_MODEL == 'ollama' else None
            }
        }